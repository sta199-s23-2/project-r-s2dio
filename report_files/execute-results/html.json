{
  "hash": "97ce52836d59bcaec1aa1bc4066088a2",
  "result": {
    "markdown": "---\ntitle: \"Project title\"\nsubtitle: \"Report\"\nformat: html\neditor: visual\nexecute:\n  echo: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.0 \n✔ tibble  3.2.1      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.3     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncbb <- read_csv(\"data/cbb.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 2455 Columns: 24\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): TEAM, CONF, POSTSEASON\ndbl (21): G, W, ADJOE, ADJDE, BARTHAG, EFG_O, EFG_D, TOR, TORD, ORB, DRB, FT...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\n**Dataset 2 (D1 college basketball)**\n\n**Introduction and data**\n\nAs Duke students, it goes without saying that Duke basketball adds on to our unique college experience. Noting Duke mens basketball's historical successes, we have grown interested in researching more about other Division 1 mens basketball programs in universities throughout the country.\n\nThe data that we will be utilizing is sourced from the Division I college basketball seasons from the years of 2013-2019. It was found in the open source data site, Kaggle. The data was scraped from http://barttorvik.com/trank.php#. This data was cleaned up in 2021, in which the COVID seasons were not included in the dataset.\n\nThe dataset has various variables that characterize different Division I basketball teams--- such as the university they represent and the conference in which they belong. Some of the observations within the dataset include the number of games played, the number of games won, power rating, as well as the stats of the team in a particular season.\n\n**Methodology**\n\n**Our research question: \"Which Division 1 basketball conference has the highest overall success rate from the 2013-2019 seasons? And which best factors (other than wins)--- (offensive/ defensive efficiency, 2pt and 3pt field goal success, steal rate, turnover rate, etc)--- best predict overall regular season success from 2013 to 2019? And does this also predict (better predict/ worse predict) post season success?\"**\n\n-- How do you plan to answer your research question?\n\n-- Prediction? Inference? Both?\n\n**Our research question: \"How does regular season adjusted offensive efficiency, and regular season adjusted defensive efficiency correlate to being a 1-seed team and post season success?\"**\n\nOur central research question is addressed through the analysis of the factors that best predict overall regular season success from 2013 to 2019. We might be able to filter out the different factors that play a role in each program's success and determine their 'weight' in assigning regular season rankings. This processes is then applied to investigate if such factor better predicts post season success/ pre-season rankings for the next basketball season.\n\n**Results**\n\n-- What are you finding out? We are finding out the correlation between seeds when predicted by adjusted offensive efficiency and adjusted defensive efficiency, as well as finding which predictor is the best (out of adjusted offensive efficiency, adjusted defensive efficiency, or both).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#| label: rename-cbb\n#| label: loading_in_data\n\ncbb_new <- cbb |>\n  rename(\"Adjusted Offensive Efficiency\" = \"ADJOE\", \"Effective Field Goal\" = \"EFG_O\", \"Wins Above Bubble\" = \"WAB\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncbb |>\n  ggplot(aes(x = ADJOE,\n             y = SEED)) +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1979 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](report_files/figure-html/visualization-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncbb |>\n  ggplot(aes(x = ADJDE,\n             y = SEED)) +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1979 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](report_files/figure-html/visualization-2.png){width=672}\n:::\n:::\n\n::: {.cell lable='linear-reg'}\n\n```{.r .cell-code}\nSEED_Model_1 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(SEED ~ ADJOE, data = cbb)\n\nSEED_Model_2 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(SEED ~ ADJDE, data = cbb)\n\nSEED_Model_3 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(SEED ~ ADJOE * ADJDE, data = cbb)\n\nSEED_Model_1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nparsnip model object\n\n\nCall:\nstats::lm(formula = SEED ~ ADJOE, data = data)\n\nCoefficients:\n(Intercept)        ADJOE  \n    69.9247      -0.5482  \n```\n:::\n\n```{.r .cell-code}\nSEED_Model_2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nparsnip model object\n\n\nCall:\nstats::lm(formula = SEED ~ ADJDE, data = data)\n\nCoefficients:\n(Intercept)        ADJDE  \n   -49.5214       0.6034  \n```\n:::\n\n```{.r .cell-code}\nSEED_Model_3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nparsnip model object\n\n\nCall:\nstats::lm(formula = SEED ~ ADJOE * ADJDE, data = data)\n\nCoefficients:\n(Intercept)        ADJOE        ADJDE  ADJOE:ADJDE  \n  183.58562     -1.98010     -1.29158      0.01587  \n```\n:::\n:::\n\n\nModel1 (predicting seed based on adjusted offensive efficiency)\n\n$\\widehat{SEED} = 69.90 - 0.55*ADJOE$\n\nModel2 (predicting seed based on adjusted defensive efficiency)\n\n$\\widehat{SEED} = -49.52 + 0.60*ADJDE$\n\nModel3 (predicting seed based on adjusted offensive and defensive efficiency)\n\n$\\widehat{SEED} = -183.59 - 1.98*ADJOE - 1.29*ADJDE + 0.02*ADJOE*ADJDE$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSEED_Model_1 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(SEED ~ ADJOE, data = cbb) |>\n  glance() |>\n  pull(adj.r.squared)\n\nSEED_Model_2 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(SEED ~ ADJDE, data = cbb) |>\n  glance() |>\n  pull(adj.r.squared)\n\nSEED_Model_3 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(SEED ~ ADJOE * ADJDE, data = cbb) |>\n  glance() |>\n  pull(adj.r.squared)\n\nSEED_Model_1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5544491\n```\n:::\n\n```{.r .cell-code}\nSEED_Model_2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4853405\n```\n:::\n\n```{.r .cell-code}\nSEED_Model_3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8094014\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nSEED_Model_1 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(SEED ~ ADJOE, data = cbb) |>\n  glance() |>\n  pull(AIC)\n\nSEED_Model_2 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(SEED ~ ADJDE, data = cbb) |>\n  glance() |>\n  pull(AIC)\n\nSEED_Model_3 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(SEED ~ ADJOE * ADJDE, data = cbb) |>\n  glance() |>\n  pull(AIC)\n\nSEED_Model_1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2438.484\n```\n:::\n\n```{.r .cell-code}\nSEED_Model_2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2507.12\n```\n:::\n\n```{.r .cell-code}\nSEED_Model_3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2036.28\n```\n:::\n:::\n\n\nThe interactive model (with both adjusted offensive and defensive efficiency) is the best model with the highest adjusted r -squared value. Adjusted offensive efficiency is the second best predictor closely followed by defensive efficiency (but both are individually less correlated with their seed). This means that between offensive and defensive efficiency is slightly more important when it comes to seeding, but both combined are the most important when it comes to predicting seed. These results do match our hypothesis which again is \"We predicted that, in regular season, teams with higher adjusted offensive efficiency & lower adjusted defensive efficiency were likelier to be 1-seed teams and make later playoff rounds.\"\n",
    "supporting": [
      "report_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}